<template>
  <p>
      The <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron"><b>Multi
      -Layer Perceptron</b></a> is not structurally different from a
      <a href="https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks">
      Deep Neural Network</a>, but there's some differences in the parameters
      initialization, in the backpropagation algorithms and in some other tricks.
      In this case, there's a single hidden layer of 10 units between the input
      and output.
  </p>
  <img src="images/add_MLP.png"/>
  <img src="images/sub_MLP.png"/>
  <img src="images/mul_MLP.png"/>
  <img src="images/div_MLP.png"/>
</template>
