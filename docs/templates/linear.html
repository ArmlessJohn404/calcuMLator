<template >
    <p>
        In <a href="https://en.wikipedia.org/wiki/Linear_regression"><b>linear
        regression</b></a>, the computer tries to find a straight line that fits
        the dataset, in this case a plane, since the input data have two dimensions.
    </p>
    <p>For sum and subtraction it fits perfectly the function</p>
    <p><b>z(x, y) = θ<sub>0</sub> + θ<sub>1</sub>x + θ<sub>2</sub>y</b></p>
    <p>and finds the parameters</p>
    <p>sum: <b>θ<sub>0</sub> = 0</b>, <b>θ<sub>1</sub> = 1</b>, <b>θ<sub>2</sub> = 1</b>.</p>
    <p>subtraction: <b>θ<sub>0</sub> = 0</b>, <b>θ<sub>1</sub> = 1</b>, <b>θ<sub>2</sub> = -1</b>.</p>
    <img src="images/add_linear.png"/>
    <img src="images/sub_linear.png"/>
    <p>
      This method can only fit straight lines and planes, it's impossible to fit the
      <b>multiplication</b> and <b>division</b> curves without providing polynomial
      features.
    </p>
    <img src="images/mul_linear.png"/>
    <p>
      It's possible to see the difference between the expected <b>multiplication</b>
      (gray) and the fitted plane with linear regression.
    </p>
    <img src="images/div_linear.png"/>
    <p>The best fit for both <b>multiplication</b> and <b>division</b> is a plane
      close to 0 with a no inclination. All coefficients are approximatelly 0.
    </p>
    <p>
      Several regressors in this project fits a plane in the data. Their complexity
      doesn't help to fit a better curve over the data.
    </p>
</template>
