<template>
  <p>
    The <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization"><b>Ridge
    Regression</b></a> is very similar to <b>Linear Regression</b>,
    but introduces a <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">
    regularization</a> term to avoid <a href="https://en.wikipedia.org/wiki/Overfitting">
    over-fitting</a> the data, specially with higher order regressions. In our
    case this regularization does nothing.
  </p>
  <p>
      The coefficients are the same to those of <b>Linear Regression</b> with
      the addition of the regularization parameter.
  </p>
  <p>
      This method differs from <a href="lasso.html">Lasso Regression</a> because
      the penalty function is different
  </p>
  <p>
    This method has a built in <a href="http://scikit-learn.org/stable/modules/cross_validation.html">cross validator</a>, but the regualization in this case is useless.
  </p>
  <img src="images/add_ridge.png"/>
  <img src="images/sub_ridge.png"/>
  <img src="images/mul_ridge.png"/>
  <img src="images/div_ridge.png"/>
</template>
